{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6bK1uJ9i6BN"
      },
      "source": [
        "## Test and Eval notebook\n",
        "\n",
        "EECS MSc Project - Research Based - 2023 <br/><br/>\n",
        "An Incremental Batch Learning Performance Assessment of CDS Implied Volatility n-step Estimation Approaches <br/><br/> Robert Taylor, Queen Mary, UoL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFzsVerO5jwb",
        "outputId": "ded09031-899e-4203-f51e-1438077e76b2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install loguru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqmEwUKt5fbt",
        "outputId": "40ff7acf-0514-4ca8-c0ce-d8e07f309197"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from loguru import logger\n",
        "import contextlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import table\n",
        "from contextlib import redirect_stdout, redirect_stderr\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from models import SVM, TFT_GRU, LGBM, Naive\n",
        "from utils import ForecastStats, reconstruct_levels, rolling_test, plot_predictions_vs_actuals, plot_residuals, plot_residuals_violin\n",
        "\n",
        "# set base dir to whatever\n",
        "base_dir = '/content/drive/My Drive/Risk Forecasting'\n",
        "\n",
        "sys.path.append(base_dir)\n",
        "\n",
        "logger.remove() #low verbosity\n",
        "logger.add(sys.stderr, level=\"ERROR\")\n",
        "\n",
        "# matplotlib in latex style\n",
        "plt.rc('font', family='serif')\n",
        "plt.rc('text', usetex=False)\n",
        "plt.rc('mathtext', fontset='stix')\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name:\n",
        "    print(f'{device_name} found')\n",
        "else:\n",
        "    print(\"No GPU found\")\n",
        "\n",
        "feature_matrix_path, target_vector_path = os.path.join(base_dir, 'features.pkl'), os.path.join(base_dir, 'RESPONSE Main 1m.xls')\n",
        "\n",
        "feature_matrix = pd.read_pickle(feature_matrix_path)\n",
        "target_vector = (pd.read_excel(target_vector_path, skiprows=range(6)).rename(columns=lambda x: x.strip()).assign(**{'Effective date': lambda df: pd\n",
        "                .to_datetime(df['Effective date'], errors='coerce')}).dropna(subset=['Effective date']).set_index('Effective date'))\n",
        "\n",
        "feature_matrix.index = pd.to_datetime(feature_matrix.index, errors='coerce')\n",
        "target_vector.index = pd.to_datetime(target_vector.index, errors='coerce')\n",
        "\n",
        "# Take ln for stationarity\n",
        "target_vector = np.log(target_vector).diff().dropna()\n",
        "\n",
        "# set sample range and take intersection\n",
        "train_index = feature_matrix.index.intersection(target_vector.index)[:-42]\n",
        "\n",
        "X = feature_matrix.loc[train_index]\n",
        "y = target_vector.loc[train_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stO5t_yktRvV",
        "outputId": "d2bc640b-aa11-42a7-d53b-409059cf20df"
      },
      "outputs": [],
      "source": [
        "X = X.iloc[:, :5] # n features\n",
        "\n",
        "print(f\"X shape: {X.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL4sL-hPZWHh"
      },
      "source": [
        "### test loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XjEYfcGYFyN"
      },
      "outputs": [],
      "source": [
        "predictions = 42  # subset at end of sliced observations dedicated to estimates (model will be fit on observations - predictions)\n",
        "sequence_length = 5  # length of sequences (set to 5 for trading week)\n",
        "window = 42\n",
        "log_path = os.path.join(base_dir, 'full_log.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut-eHS095fbz",
        "outputId": "56aa8c69-e616-4599-d548-69a99fbf8e60"
      },
      "outputs": [],
      "source": [
        "with open(log_path, 'w') as f:\n",
        "    with redirect_stdout(f), redirect_stderr(f):\n",
        "        raw_metrics = {}\n",
        "        levels_metrics = {}\n",
        "        model_name_suffix = f' w {window}-period'\n",
        "\n",
        "        # Naive model\n",
        "        model_name = 'Na√Øve Forecast'\n",
        "        raw_metrics[model_name] = rolling_test(\n",
        "            Naive, X, y, chunk=(window + predictions), predictions=predictions, model_name=model_name\n",
        "            )\n",
        "\n",
        "        levels_metrics[model_name] = reconstruct_levels(target_vector, raw_metrics[model_name])\n",
        "\n",
        "        # SVM model\n",
        "        model_name = f'SVM{model_name_suffix}'\n",
        "        with contextlib.redirect_stdout(sys.__stdout__):\n",
        "            print(f'Training and rolling test for {model_name}')\n",
        "        raw_metrics[model_name] = rolling_test(\n",
        "            SVM, X, y, chunk=(window + predictions), predictions=predictions, sequence_length=sequence_length, model_name=model_name\n",
        "            )\n",
        "\n",
        "        levels_metrics[model_name] = reconstruct_levels(target_vector, raw_metrics[model_name])\n",
        "\n",
        "        # LightGBM model\n",
        "        model_name = f'LightGBM{model_name_suffix}'\n",
        "        with contextlib.redirect_stdout(sys.__stdout__):\n",
        "            print(f'Training and rolling test for {model_name}')\n",
        "        raw_metrics[model_name] = rolling_test(\n",
        "            LGBM, X, y, chunk=(window + predictions), predictions=predictions,sequence_length=sequence_length, model_name=model_name\n",
        "            )\n",
        "\n",
        "        levels_metrics[model_name] = reconstruct_levels(target_vector, raw_metrics[model_name])\n",
        "\n",
        "        # TFT-GRU model\n",
        "        model_name = f'TFT-GRU{model_name_suffix}'\n",
        "        with contextlib.redirect_stdout(sys.__stdout__):\n",
        "            print(f'Training and rolling test for {model_name}')\n",
        "        with tf.device('/device:GPU:0'):\n",
        "            raw_metrics[model_name] = rolling_test(\n",
        "                TFT_GRU, X, y, chunk=(window + predictions), predictions=predictions,sequence_length=sequence_length, model_name=model_name\n",
        "                )\n",
        "\n",
        "        levels_metrics[model_name] = reconstruct_levels(target_vector, raw_metrics[model_name])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQV42BT3dqRF"
      },
      "source": [
        "### eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RZSyQ1snYMrD",
        "outputId": "39d64d34-d0d5-401c-8765-a113d6b96c48"
      },
      "outputs": [],
      "source": [
        "# metrics, log returns\n",
        "forecast_stats = ForecastStats(raw_metrics, X)\n",
        "result_table = forecast_stats.calculate_forecast_stats()\n",
        "\n",
        "result_table_path = os.path.join(base_dir, 'result_table.tex')\n",
        "with open(result_table_path, 'w') as f:\n",
        "    f.write(result_table.to_latex(index=False))\n",
        "\n",
        "result_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AjtXDUiUYPkf",
        "outputId": "95d8da40-f4cf-4d1d-df90-fe4d8803ad52"
      },
      "outputs": [],
      "source": [
        "# metrics, levels\n",
        "level_metrics_table = forecast_stats.calculate_level_metrics(levels_metrics)\n",
        "\n",
        "level_metrics_table_path = os.path.join(base_dir, 'level_metrics_table.tex')\n",
        "with open(level_metrics_table_path, 'w') as f:\n",
        "    f.write(level_metrics_table.to_latex(index=False))\n",
        "\n",
        "level_metrics_table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQTA4uLdg97i"
      },
      "source": [
        "### plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xkEbEH5EhFvL"
      },
      "outputs": [],
      "source": [
        "models = ['TFT-GRU', 'SVM', 'LightGBM']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0vo_w0TjcdII",
        "outputId": "566e0b24-d7b7-4def-d6d3-8acd5fc0dfc1"
      },
      "outputs": [],
      "source": [
        "plot_predictions_vs_actuals(levels_metrics, models, model_name_suffix, window)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7Drz9YrXfvt7",
        "outputId": "0e8f1a02-f58a-447f-a5d9-5a0ae46b54b8"
      },
      "outputs": [],
      "source": [
        "plot_residuals(raw_metrics, models, model_name_suffix, window)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ztf_pS0wg8Y4",
        "outputId": "e2c04dfe-0204-4bcd-fbd8-71c9351e0d37"
      },
      "outputs": [],
      "source": [
        "all_residuals = []\n",
        "for model in models:\n",
        "    suffix = f'{model}{model_name_suffix}'\n",
        "    residuals = np.array(raw_metrics[suffix]['actuals']) - np.array(raw_metrics[suffix]['forecasts'])\n",
        "    all_residuals.append(residuals)\n",
        "\n",
        "plot_residuals_violin(all_residuals, models, window)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eU44sqbVnTJi",
        "outputId": "ee3dfb18-e58e-4783-884d-af54e1c78bb2"
      },
      "outputs": [],
      "source": [
        "files = [os.path.join(base_dir, 'result_table2.png'), os.path.join(base_dir, 'level_metrics_table2.png')]\n",
        "\n",
        "for df, file_name in zip([result_table, level_metrics_table], files):\n",
        "    fig, ax = plt.subplots(figsize=(8, 3))\n",
        "    ax.axis('tight')\n",
        "    ax.axis('off')\n",
        "    tbl = table(ax, df, loc='center', cellLoc='center', colWidths=[0.2]*len(df.columns))\n",
        "    tbl.auto_set_font_size(False)\n",
        "    tbl.set_fontsize(12)\n",
        "    tbl.scale(1.2, 1.2)\n",
        "    plt.savefig(file_name, bbox_inches='tight')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
